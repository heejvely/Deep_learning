{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"순환 신경망.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1HAf-0vEzteJ8lO8W83IFr3gMvWSXawWA","authorship_tag":"ABX9TyPy6/BGHB0h2TkHZB0Y6buG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["### 라이브러리 임포트"],"metadata":{"id":"S7KysGM7QNUr"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"my2eHkvognIj","executionInfo":{"status":"ok","timestamp":1642825196551,"user_tz":-540,"elapsed":300,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"outputs":[],"source":["from typing import *\n","import numpy as np\n","from numpy import ndarray"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from IPython import display\n","plt.style.use('seaborn-white')\n","%matplotlib inline\n","\n","from copy import deepcopy\n","from collections import deque"],"metadata":{"id":"jeB7nHkWQMjc","executionInfo":{"status":"ok","timestamp":1642825196802,"user_tz":-540,"elapsed":2,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from scipy.special import logsumexp"],"metadata":{"id":"-WOzrIRhQlSQ","executionInfo":{"status":"ok","timestamp":1642825197305,"user_tz":-540,"elapsed":504,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### 활성화 함수"],"metadata":{"id":"tUQwCKqYQwYU"}},{"cell_type":"code","source":["def sigmoid(x: ndarray):\n","    return 1 / (1 + np.exp(-x))\n","\n","\n","def dsigmoid(x: ndarray):\n","    return sigmoid(x) * (1 - sigmoid(x))\n","\n","\n","def tanh(x: ndarray):\n","    return np.tanh(x)\n","\n","\n","def dtanh(x: ndarray):\n","    return 1 - np.tanh(x) * np.tanh(x)\n","\n","\n","def softmax(x, axis=None):\n","    return np.exp(x - logsumexp(x, axis=axis, keepdims=True))\n","\n","\n","def batch_softmax(input_array: ndarray):\n","    out = []\n","    for row in input_array:\n","        out.append(softmax(row, axis=1))\n","    return np.stack(out)"],"metadata":{"id":"ZoJrURt0QyH8","executionInfo":{"status":"ok","timestamp":1642825197305,"user_tz":-540,"elapsed":17,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 자동 미분"],"metadata":{"id":"3-epKO4KlKt6"}},{"cell_type":"code","source":["a = np.array([3,3])\n","print(\"Addition using '__add__': \", a.__add__(4))\n","print(\"Addition using '+': \", a + 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OfYNFh4lXrX","executionInfo":{"status":"ok","timestamp":1642825197305,"user_tz":-540,"elapsed":16,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"outputId":"452040bf-6d91-4ae4-ca83-3396d1bcf1c3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Addition using '__add__':  [7 7]\n","Addition using '+':  [7 7]\n"]}]},{"cell_type":"code","source":["Numberable = Union[float, int]\n","\n","def ensure_number(num: Numberable):\n","  if isinstance(num, NumberWithGrad):\n","    return num\n","  else:\n","    return NumberWithGrad(num)\n","\n","class NumberWithGrad(object):\n","\n","  def __init__(self,\n","               num: Numberable,\n","               depends_on: List[Numberable] = None,\n","               creation_op: str = ''):\n","    self.num = num\n","    self.grad = None\n","    self.depends_on = depends_on or []\n","    self.creation_op = creation_op\n","\n","  def __add__(self,\n","              other: Numberable):\n","\n","    return NumberWithGrad(self.num + ensure_number(other).num,\n","                          depends_on = [self, ensure_number(other)],\n","                          creation_op = 'add')\n","  def __mul__(self,\n","              other: Numberable = None):\n","    \n","    return NumberWithGrad(self.num * ensure_number(other).num,\n","                          depends_on = [self, ensure_number(other)],\n","                          creation_op = 'mul')\n","    \n","  def backward(self, backward_grad: Numberable = None) -> None:\n","    if backward_grad is None:   # backward가 처음 호출됨\n","      self.grad = 1\n","    else:\n","      # 이 부분에서 기울기가 누적됨\n","      # 기울기 정보가 아직 없다면 backward_grad로 설정\n","      if self.grad is None:\n","        self.grad = backward_grad\n","      # 기울기 정보가 있다면 기존 기울기값에 backward_grad를 더함\n","      else:\n","        self.grad += backward_grad\n","\n","    if self.creation_op == 'add':\n","      # self.grad를 역방향으로 전달함\n","      # 둘 중 어느 요소를 증가시켜도 출력이 같은 값만큼 증가함\n","      self.depends_on[0].backward(self.grad)\n","      self.depends_on[1].backward(self.grad)\n","\n","    if self.creation_op == 'mul':\n","      \n","      # 첫 번째 요소에 대한 미분 계산\n","      new = self.depends_on[1] * self.grad\n","      # 이 요소에 대한 미분을 역방향으로 전달\n","      self.depends_on[0].backward(new.num)\n","\n","      # 두 번째 요소에 대한 미분 계산\n","      new = self.depends_on[0] * self.grad\n","      # 이 요소에 대한 미분을 역방향으로 전달\n","      self.depends_on[1].backward(new.num)"],"metadata":{"id":"lW4RWd14lyIQ","executionInfo":{"status":"ok","timestamp":1642825197306,"user_tz":-540,"elapsed":13,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["a = NumberWithGrad(3)\n","\n","b = a * 4\n","c = b + 5"],"metadata":{"id":"w37P8jlIqhwR","executionInfo":{"status":"ok","timestamp":1642825197306,"user_tz":-540,"elapsed":13,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["c.backward()"],"metadata":{"id":"dws-7vS9rELI","executionInfo":{"status":"ok","timestamp":1642825197307,"user_tz":-540,"elapsed":13,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(a.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73QKHcY0rFg2","executionInfo":{"status":"ok","timestamp":1642825197307,"user_tz":-540,"elapsed":13,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"outputId":"c077be5a-b960-4549-9449-1002aa908860"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","1\n"]}]},{"cell_type":"markdown","source":["자동 미분 수행 과정"],"metadata":{"id":"xWYc7jSyth9d"}},{"cell_type":"code","source":["a = NumberWithGrad(3)\n","\n","b = a * 4\n","c = b + 3\n","d = c * (a + 2)\n","\n","\"\"\"\n","d = (4a + 3) x (a + 2)\n","  = 4a²+ 11a + 6\n","\n","미적분 시, 도함수\n","  = 8a + 11\n","a = 3 일 때, 미분은 8 x 3 + 11 = 35가 된다.\n","\"\"\""],"metadata":{"id":"IRV5tg6BrK-9","executionInfo":{"status":"ok","timestamp":1642825197307,"user_tz":-540,"elapsed":11,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"a9fcb25e-69fd-4d7c-993b-75b401eb6855"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nd = (4a + 3) x (a + 2)\\n  = 4a²+ 11a + 6\\n\\n미적분 시, 도함수\\n  = 8a + 11\\na = 3 일 때, 미분은 8 x 3 + 11 = 35가 된다.\\n'"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["def forward(num: int):\n","  b = num * 4\n","  c = b + 3\n","  return c * (num + 2)\n","\n","print(round((forward(3.01) - forward(2.99)) / 0.02, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOYFUF39toVW","executionInfo":{"status":"ok","timestamp":1642825197307,"user_tz":-540,"elapsed":10,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"outputId":"31b1cfde-6ce1-4b3a-f0e3-7f98093dabd6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["35.0\n"]}]},{"cell_type":"code","source":["a = NumberWithGrad(3)\n","\n","b = a * 4\n","c = b + 3\n","d = (a + 2)\n","e = c * d\n","e.backward()\n","\n","print(a.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOlshRnHvERq","executionInfo":{"status":"ok","timestamp":1642825197308,"user_tz":-540,"elapsed":9,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"outputId":"8011d891-e59d-42b8-dc63-9ef9bd22070d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["35\n"]}]},{"cell_type":"markdown","source":["#### 자동 미분의 원리\n","자동 미분의 목적은 연산 대신 숫자, ndarray, Tensor 등 데이터 객체 자신이 해석의 대상이 되는 것이다.\n","\n","모든 자동 미분 기법의 공통적인 특징은 다음과 같다.\n","\n","- 연산 대상이 되는 실제 데이터를 감싼 래퍼 클래스를 만든다. 우리가 만든 프레임워크에서는 float와 int를 감싸는 NumberWithGrad 클래스를 만들었다. 파이토치에서도 비슷한 역할을 하는 Tensor 클래스가 있다.\n","\n","- 덧셈, 곱셈, 행렬곱 등의 연산이 래퍼 클래스를 객체를 반환하도록 재정의한다. 앞서 본 예제에서도 NumberWithGrad 객체끼리의 연산이나 NumberWithGrad와 float, int의 연산 모두 NumberWithGrad 객체를 반환하도록 연산을 재정의했다.\n","\n","- NumberWithGrad 클래스는 순방향 계산 결과에 따라 기울기 계산에 필요한 정보를 포함해야 한다. 앞 예제에서는 인스턴스 변수 creation_op에 해당 객체가 생성된 연산 정보를 담았다.\n","\n","- 역방향 계산 과정에서 기울기는 기반 데이터 타입으로 전달된다. 이 예제에서는 기울기가 NumberWithGrad 타입이 아니라 float와 int 타입이다.\n","\n","- 이번 절 처음에서 언급했듯이 자동 미분으로 순방향 계산 과정의 중간 결과를 재사용할 수 있다. 앞 예제에서도 a를 문제없이 두 번 사용했다. 다음 그 코드가 핵심 원리다.\n","\n","```\n","if self.grad is None:\n","  self.grad = backward_grad\n","else:\n","  self.grad += backward_grad\n","```\n","\n","- backward_grad로 기울기를 처음 전달받으면 이 값으로 지정된 기울기 값을 초기화하고, 기울기를 전달 받은 적이 있다면 기존 값에 전달받은 값을 더한다. NumberWithGrad 객체는 모델 안에서 재사용된 값의 기울기를 누적한다."],"metadata":{"id":"GZx1hHQLw6uC"}},{"cell_type":"markdown","source":["#### 순환 신경망 구현을 위한 첫 번째 클래스: RNNLayer\n","\n","1. data[:, 0, :]로 시작하는 두 번째 축에 늘어선 2차원 배열을 하나 선택한다. 이렇게 선택된 배열의 모양은 (batch_size, num_features)가 된다.\n","\n","2. RNNLayer 객체의 '내부 상태'를 (batch_size, hidden_size) 모양으로 초기화한다. 이 상태는 연속열이 한 요소씩 입력되는 과정에서 지속적으로 수정된다. 그러므로 이 ndarray 객체는 이 층이 현재 시각까지 입력받은 데이터에 대한 '누적된 정보'를 나타낸다.\n","\n","3. 1과 2에 나온 2개의 ndarray 객체로 첫 번째 시각에 대한 순방향 계산을 수행한다. 우리가 만들 RNNLayer는 일반적인 Dense층처럼 입력과 출력의 모양이 다르게 설계된다. 따라서 출력의 모양은 (batch_size, num_outputs)가 된다. 관찰을 하나씩 입력하며 신경망 안에 들어 있는 표현을 수정한다. 이때 RNNLayer도 각 시각마다 (batch_size, hidden_size) 모양의 ndarray 객체를 출력한다.\n","\n","4. 데이터의 두 번째 축에서 그 다음 2차원 배열(data[:, 1, :])을 선택한다.\n","\n","5. 첫 번째 시각에서 출력된 표현과 데이터로 두 번째 시각의 순방향 계산을 수행하고 그 결과로 (batch_size, num_outputs) 모양의 출력을 내놓는다. 또한 (batch_size, hidden_size) 모양의 표현도 수정된다.\n","\n","6. sequence_length번 동안 이 과정을 반복한다. 그 다음 출력값을 모아 (batch_size, sequence_length, num_outputs) 모양으로 합친다."],"metadata":{"id":"6zl9KFQj1LS3"}},{"cell_type":"markdown","source":["#### 순환 신경망 구현을 위한 두 번째 클래스: RNNNode\n","앞의 동작 내용에 따르면 RNNNode 클래스는 다음과 같은 입출력을 갖는 forward 메서드를 갖춰야 한다.\n","\n","- 입력: 2개의 ndarray 객체\n","  - 모양이 [batch_size, num_features]인 신경망의 입력\n","  - 모양이 [batch_size, hidden_size]인 해당 시각의 표현\n","\n","- 출력: 2개의 ndarray 객체\n","  - 모양이 [batch_size, num_outputs]인 해당 시각의 출력\n","  - 모양이 [batch_size, hidden_size]인 해당 시각에 수정된 표현"],"metadata":{"id":"9Z1mowko2OVa"}},{"cell_type":"markdown","source":["#### 두 클래스 결합하기\n","\n","RNNLayer 객체는 RNNNode 객체의 리스트를 내부에 포함하며 다음과 같은 입출력을 갖는 forward 메서드를 갖춰야 한다.\n","\n","- 입력: 모양이 [batch_size, sequence_length, num_features]인 관찰의 연속열로 구성된 배치\n","- 출력: 모양이 [batch_size, sequence_length, num_outputs]인 층의 출력"],"metadata":{"id":"WH_yTvgX2s2A"}},{"cell_type":"markdown","source":["#### 역방향 계산\n","\n","순환 신경망의 역전파 알고리즘은 흔히 BPTT(Backpropagation through time)라는 별도의 알고리즘으로 취급된다. 순방향 계산 과정에서 데이터가 흐르는 방식을 잘 기억하면, 같은 방식으로 역뱡향 계산 과정도 설명할 수 있다. 입력이 흘렀던 방식의 정확히 반대 방향으로 기울기를 전달하면 된다.\n","\n","[순방향 계산 과정]\n","\n","1. 각 모양이 (features_size, sequence_length)인 관찰로 구성된 배치로 시작한다.\n","2. 이 입력을 sequence_length개의 요소로 분할한 다음, 한 번에 하나씩 신경망에 입력한다.\n","3. 각 요소가 모든 층을 통과하면 output_size 차원의 출력으로 변환된다.\n","4. 이와 같은 시점에 층의 내부 상태가 다음 시각의 입력으로 전달된다.\n","5. 1~4의 과정을 sequence_length시각 동안 반복하면 전체 (output_size, sequence_length) 크기의 출력이 나온다.\n","\n","<br/>\n","\n","[역전파 계산 과정]\n","\n","1. 모양이 [output_size, sequence_length]인 기울기로 시작한다. 이 기울기는 출력(크기가 [output_size, sequence_length])의 각 요소가 해당 배치의 손실값에 미친 영향을 의미한다.\n","2. 기울기를 sequence_length개의 요소로 분할한 다음, 한 번에 하나씩 신경망의 출력층에 입력하여 층을 거슬러 올라간다.\n","3. 각 요소의 기울기를 모든 층에 통과시킨다.\n","4. 마찬가지로 각 층은 해당 시각의 내부 상태에 대한 손실의 기울기를 자신의 이전 시각의 계산으로 전달한다.\n","5. 1~4의 과정을 sequence_length시각 동안 반복해서 신경망 맨 앞까지 기울기를 전달한다. 순방향 신경망처럼 이 과정에서 각 가중치에 대한 손실의 기울기가 계산된다."],"metadata":{"id":"6A6pj_NT3O8s"}},{"cell_type":"markdown","source":["### 헬퍼함수"],"metadata":{"id":"US7sfeFoSsTq"}},{"cell_type":"code","source":["def assert_same_shape(output: ndarray,\n","                      output_grad: ndarray):\n","  assert output.shape == output_grad.shape, \\\n","  f\"\"\"\n","  두 ndarray의 모양이 같아야 하는데,\n","  첫 번째 ndarray의 모양은 {tuple(output_grad.shape)}이고,\n","  두 번째 ndarray의 모양은 {tuple(output.shape)}이다.\n","  \"\"\"\n","  return None"],"metadata":{"id":"fvA5_kNlL-Uh","executionInfo":{"status":"ok","timestamp":1642825197308,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### RNNOptimizer 클래스"],"metadata":{"id":"CJVHyX9BRISf"}},{"cell_type":"code","source":["class RNNOptimizer(object):\n","  def __init__(self,\n","               lr: float = 0.01,\n","               gradient_clipping: bool = True) -> None:\n","    self.lr = lr\n","    self.gradient_clipping = gradient_clipping\n","    self.first = True\n","\n","  def step(self)-> None:\n","    \n","    for layer in self.model.layers:\n","      for key in layer.params.keys():\n","\n","        if self.gradient_clipping:\n","          np.clip(layer.params[key]['deriv'], -2, 2, layer.params[key]['deriv'])\n","\n","        self._update_rule(param = layer.params[key]['value'],\n","                          grad = layer.params[key]['deriv'])\n","        \n","  def _update_rule(self, **kwargs) -> None:\n","    raise NotImplementedError()"],"metadata":{"id":"YsZa739jRKkD","executionInfo":{"status":"ok","timestamp":1642825197308,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### SGD, AdaGrad 클래스"],"metadata":{"id":"Lj0-x0F0RBNa"}},{"cell_type":"code","source":["class SGD(RNNOptimizer):\n","    def __init__(self,\n","                 lr: float = 0.01,\n","                 gradient_clipping: bool = True) -> None:\n","        super().__init__(lr, gradient_clipping)\n","\n","    def _update_rule(self, **kwargs) -> None:\n","\n","        update = self.lr*kwargs['grad']\n","        kwargs['param'] -= update"],"metadata":{"id":"l4iZXj1DRD-B","executionInfo":{"status":"ok","timestamp":1642825197308,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class AdaGrad(RNNOptimizer):\n","    def __init__(self,\n","                 lr: float = 0.01,\n","                gradient_clipping: bool = True) -> None:\n","        super().__init__(lr, gradient_clipping)\n","        self.eps = 1e-7\n","\n","    def step(self) -> None:\n","        if self.first:\n","            self.sum_squares = {}\n","            for i, layer in enumerate(self.model.layers):\n","                self.sum_squares[i] = {}\n","                for key in layer.params.keys():\n","                    self.sum_squares[i][key] = np.zeros_like(layer.params[key]['value'])\n","            \n","            self.first = False\n","\n","        for i, layer in enumerate(self.model.layers):\n","            for key in layer.params.keys():\n","                \n","                if self.gradient_clipping:\n","                    np.clip(layer.params[key]['deriv'], -2, 2, layer.params[key]['deriv'])\n","                \n","                self._update_rule(param=layer.params[key]['value'],\n","                                  grad=layer.params[key]['deriv'],\n","                                  sum_square=self.sum_squares[i][key])\n","\n","    def _update_rule(self, **kwargs) -> None:\n","\n","            # 이전 기울기의 제곱의 합을 계산\n","            kwargs['sum_square'] += (self.eps +\n","                                     np.power(kwargs['grad'], 2))\n","\n","            # 이전 5개 기울기의 제곱의 합으로 학습률을 수정\n","            lr = np.divide(self.lr, np.sqrt(kwargs['sum_square']))\n","\n","            # 수정된 학습률을 적용\n","            kwargs['param'] -= lr * kwargs['grad']"],"metadata":{"id":"EWsyq5mqSOvc","executionInfo":{"status":"ok","timestamp":1642825197308,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### 손실함수"],"metadata":{"id":"e8eyw3KSSY7H"}},{"cell_type":"code","source":["class Loss(object):\n","\n","    def __init__(self):\n","        pass\n","\n","    def forward(self,\n","                prediction: ndarray,\n","                target: ndarray) -> float:\n","\n","        assert_same_shape(prediction, target)\n","\n","        self.prediction = prediction\n","        self.target = target\n","\n","        self.output = self._output()\n","\n","        return self.output\n","    \n","    def backward(self) -> ndarray:\n","\n","        self.input_grad = self._input_grad()\n","\n","        assert_same_shape(self.prediction, self.input_grad)\n","\n","        return self.input_grad\n","\n","    def _output(self) -> float:\n","        raise NotImplementedError()\n","\n","    def _input_grad(self) -> ndarray:\n","        raise NotImplementedError()\n","\n","        \n","class SoftmaxCrossEntropy(Loss):\n","    def __init__(self, eps: float=1e-9) -> None:\n","        super().__init__()\n","        self.eps = eps\n","        self.single_class = False\n","\n","    def _output(self) -> float:\n","\n","        out = []\n","        for row in self.prediction:\n","            out.append(softmax(row, axis=1))\n","        softmax_preds = np.stack(out)\n","\n","        # 안정적인 계산을 위해 소프트맥스의 출력을 제한\n","        self.softmax_preds = np.clip(softmax_preds, self.eps, 1 - self.eps)\n","\n","        # 손실을 실제로 계산\n","        softmax_cross_entropy_loss = -1.0 * self.target * np.log(self.softmax_preds) - \\\n","            (1.0 - self.target) * np.log(1 - self.softmax_preds)\n","\n","        return np.sum(softmax_cross_entropy_loss)\n","\n","    def _input_grad(self) -> np.ndarray:\n","\n","        return self.softmax_preds - self.target"],"metadata":{"id":"pZ_PHKBsSZ9C","executionInfo":{"status":"ok","timestamp":1642825197309,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## RNN 코드\n","\n","1. RNN에서도 데이터는 각 층을 통과해야 한다. 각 층은 순방향 계산 과정에서 출력을 다음 층으로 전달하고, 역방향 계산 과정에서는 기울기를 이전 층으로 전달한다. 그러므로 이전의 NeuralNetwork 클래스와 같은 역할을 맡은 클래스는 layers라는 이름의 RNNLayer 객체의 리스트를 통해 다음과 같은 코드로 순방향 계산을 구현한다.\n","\n","```\n","def forward(self, x_batch: ndarray) -> ndarray:\n","\n","  assert_dim(ndarray, 3)\n","  \n","  x_out = x_batch\n","  for layer in self.layers:\n","    x_out = layer.forward(x_out)\n","  \n","  return x_out\n","```\n","\n","2. 손실을 계산하는 과정을 전과 같다. 신경망의 마지막 층에서 출력된 ndarray 객체의 값을 y_batch의 목표값과 비교한 다음, 이를 바탕으로 손실값을 계산한다. 그리고 입력에 대한 손실의 기울기를 계산하는데, 이 기울기는 출력과 모양이 같은 ndarray다. 이러려면 소프트맥스 함수가 [batch_size, sequence_length, feature_size] 모양의 ndarray를 다룰 수 있도록 수정해야 함.\n","\n","3. Trainer 클래스는 그대로 유지된다. 학습 데이터를 순화하며 입력 데이터와 출력 데이터의 배치를 선택하고 순서대로 모델에 배치를 입력해 손실값을 계산한 다음, 이 값을 통해 학습이 잘 진해오디는지 확인하고 가중치를 수정한다.\n","\n","4. Optimizer 클래스도 그대로 유지된다. 매 시각마다 params와 param_grads에서 필요한 값을 찾는 방법이 달라지겠지만, '수정규칙'(_updatte_rule 메서드에 표현된)은 그대로 사용한다."],"metadata":{"id":"8yIqSBGZ6Ti3"}},{"cell_type":"markdown","source":["#### RNNLayer 클래스\n","\n","RNNLayer는 새로운 데이터가 끊임없이 입력되며 이 정보를 반영해 지속적으로 매 시간마다 수정되는 '내부 상태'를 유지해야한다.\n","- RNNLayer는 RNNNode 객체의 리스트를 속성으로 가지며, 이 RNNNode는 연속열의 요소가 하나씩 차례대로 통과한다. 따라서 RNNNode는 연속열의 요소와 자신을 포함하는 층의 내부상태를 입력받는다.\n","- 그리고 현재 시각에 대한 해당 층의 출력을 내보내고 내부 상태를 수정한다.\n","\n","<br/>\n","\n","#### 초기화하기\n","RNNLayer 객체는 초기화를 위해 다음과 같은 정보를 받는다.\n","\n","- int 타입 hidden_size\n","- int 타입 output_size\n","- ndarray 타입 start_H(모양은 (1, hidden_size)) 이 층의 내부 상태가 저장된다.\n","\n","초기화할 때 self.first = True플래그를 설정한다. 이 플래그가 참이면 forward 메서드가 데이터로 전달받은 ndarray 객체를 \\_init_params 메서드에 전달해 파라미터를 초기화한 다음, 플래그를 거짓(self.first = False)로 설정한다."],"metadata":{"id":"OWtoCeMXBgGl"}},{"cell_type":"markdown","source":["#### forward 메서드\n","\n","- forward 메서드의 대부분은 모양이 (batch_size, sequence_length, feature_size)인 ndarray 객체 x_seq_in을 입력 받고 이 데이터를 RNNNode 객체들에 순서대로 통과시키는 코드다. 다음 코드에서 self.nodes는 이 층이 가진 RNNNode 객체의 리스트이며, H_in은 이 층의 내부 상태다.\n","\n","```\n","sequence_length = x_seq_in.shape[1]\n","\n","x_seq_out = np.zeros((batch_size, sequence_length, self.output_size))\n","\n","for t in range(sequence_length):\n","  x_in = x_seq_in[:, t, :]\n","  y_out, H_in = self.nodes[t].forward(x_in, H_in, self.params)\n","  x_seq_out[:, t, :] = y_out\n","```\n","\n","- RNNLayer의 내부 상태 H_in은 일반적으로 하나의 벡터로 표현된다. 그러나 RNNNode의 ㅇ녀산을 수행하려면 내부 상태가(batch_size, hidden_size) 모양의 ndarray여야 한다. 그러므로 순방향 계산을 시작하기 전에 다음과 같이 내부 상태를 복사한다.\n","\n","```\n","batch_size = x_seq_in.shape[0]\n","\n","H_in = np.copy(self.start_H)\n","\n","H_in = np.repeat(H_in, batch_size, axis = 0)\n","```\n","\n","- 순방향 계산이 끝난 후에는 각 관찰에 대해 계산된 내부 상태를 평균 내고, 이를 층의 새로운 내부 상태로 삼는다.\n","\n","```\n","self.start_H = H_in.mean(axis = 0, keepdims = True)\n","```\n","\n","- 위 코드에서 RNNNode의 forward 메서드가 다음과 같은 모양으 ㅣ배열 2개를 입력받는다는 것을 알게 되었다.\n","  - (batch_size, feature_size)\n","  - (batch_size, hidden_size)\n","\n","- 메서드가 반환하는 배열의 모양은 다음과 같다.\n","  - (batch_size, output_size)\n","  - (batch_size, hidden_size)"],"metadata":{"id":"x7YCwDHICiWu"}},{"cell_type":"markdown","source":["#### backward 메서드\n","\n","- forward 메서드는 x_seq_out을 반환하므로 backward 메서드는 x_seq_out과 모양이 같은 기울기인 x_seq_grad를 인자로 받는다. forward 메서드와는 반대 방향으로 이 기울기를 RNNNode 객체에 통과시킨다. 그리고 그 결과로 모양이 (batch_size, sequence_length, self.feature_size)인 배열 x_seq_in_grad를 전체 층에 대한 기울기로 반환한다.\n","\n","```\n","h_in_grad = np.zeros((batch_size, self.hidden_size))\n","\n","sequence_length = x_seq_out_grad.shape[1]\n","\n","x_seq_in_grad = np.zeros((batch_size, sequence_length, self.feature_size))\n","\n","for t in reversed(range(sequence_length)):\n","  x_out_grad = x_seq_out_grad[:, t, :]\n","  grad_out, h_in_grad = self.nodes[t].backward(x_out_grad, h_in_grad, self.params)\n","\n","x_seq_in_grad[:, t, :] = grad_out\n","```\n","\n","- 위 코드로 볼 때, RNNNode 클래스에도 backward 메서드가 있어야 한다. 이 메서드는 forward와 반대로 동작하므로 인자와 반환값이 모양이 다음과 같이 서로 바뀐다.\n","  - (batch_size, output_size)\n","  - (batch_size, hidden_size)\n","\n","- 반환값의 모양은 다음과 같다.\n","  - (batch_size, feature_size)\n","  - (batch_size, hidden_size)"],"metadata":{"id":"xjkADUcGEMsc"}},{"cell_type":"markdown","source":["#### RNNNode 클래스의 공통요소\n","\n","- 바닐라 RNN(vanilla RNN): 기본적인 RNN 구현 방법\n","- 게이트 순환 유닛(gated recurrent unit_GRU): 바닐라 RNN과 다른 RNNNode를 구현하는 방법\n","\n","- RNN의 모든 층은 순방향으로 데이터가 흘러가는 패텅이 동일하며, 매 시각마다 내부 상태를 수정한다. 차이점은 '노드'가 동작하는 내부의 세부 사항에 국한된다.\n","- RNNLayer 대신 GRULayer를 구현하면 다음 코드를 순방향 계산의 핵심 부분에 그대로 사용할 수 있다.\n","\n","```\n","sequence_length = x_seq_in.shape[1]\n","\n","x_seq_out = np.zeros((batch_size, sequence_length, self.output_size))\n","\n","for t in range(sequence_length):\n","  x_in = x_seq_in[:, t, :]\n","  y_out, H_in = self.nodes[t].forward(x_in, H_in, self.params)\n","  x_seq_ut[:, t, :] = y_out\n","```\n","구현상 차이점은 단지 self.nodes 안에 든 '노드'들이 RNNNode가 아닌 GRUNode 객체라는 점이다. backward 메서드의 코드도 동일하다.\n","\n","- RNN의 변종 중 가장 유명한 LSTM(Long Short-Term Memory) 역시 마찬가지다. 바닐라 RNN과 LSTM의 차이점은 LSTMLayer 객체가 지속적으로 기억하고 입력되는 데이터에 따라 수정하는 값이 기존의 '내부 상태'만 있던 것에서 '셀 상태'까지 한가지 추가되는 점이다. 이 차이점 때문에 LSTMLayer는 RNNLayer와 구현 코드가 약간 다르다. 이를테면 LSTMLayer는 시간의 흐름에 따른 층의 상태를 저장하는 데 다음과 같은 2개의 ndarray 객체를 사용한다.\n","\n","  - ndarray 타입 start_H(모양은 (1, hidden_size)) 층의 내부 상태를 나타냄.\n","  - ndarray 타입 start_C(모양은 (1, cell_size)) 층의 셀 상태를 나타냄.\n","\n","- 그러므로 LSTMNode 객체도 내부 상태와 셀 상태를 모두 입력으로 받는다. 따라서 순방향 계산 코드는 다음과 같다.\n","\n","```\n","y_out, H_in, C_in = self.nodes[t].forward(x_in, H_in, C_in, self.params)\n","```\n","\n","- 역방향 계산 코드는 다음과 같다.\n","\n","```\n","grad_out, h_in_grad, c_in_grad = self.nodes[t].backward(x_out_grad, h_in_grad, c_in_grad, self.params)\n","```"],"metadata":{"id":"FJRqSKkgFhaa"}},{"cell_type":"markdown","source":["#### 바닐라 RNNNode 클래스\n","\n","- RNN은 순차 데이터의 요소를 한 번에 1개씩 입력받는다. RNN이 하는 일은 새로 입력된 현재 시각의 특징과 지금까지 입력받은 정보의 누적, 이 두 가지 데이터를 결합해서 현재 시각의 목표값을 예측함과 동시에 누적된 정보를 최신 상태로 수정하는 것이다.\n","\n","- 이를 위해 RNN을 어떻게 구현해야 하는가에 대한 힌트를 일반적인 신경망에서 얻을 수 있다. 순방향 신경망의 각 층은 이전 층에서 '학습된 특징'을 전달받는다. 학습된 특징이란 최초의 특징 중 유용했던 것들의 조합이다. 층에 입력된 특징은 가중치 행렬과 곱해져서 다시 새롱누 특징을 조합한다. 그리고 그 결과값을 안정화하고 정규화하기 위해 '편향'을 더한 다음, 활성화 함수에 통과시킨다.\n","\n","- RNN에서 최신 정보로 수정된 내부 상태의 값은 입력과 이전 내부 상태값의 조합이다. 순방향 신경망에서 새로운 특징을 조합하는 과정과 같다면 계산 과정은 다음과 같다.\n","  1. 먼저 입력과 내부 상태값을 연결한다. 그 다음 이 값과 가중치 행렬을 곱하고, 편향을 더한 다음, 활성화 함수 Tanh을 거친다. 그리고 결과값을 새로운 내부 상태로 삼는다.\n","  2. 그 다음에는 새로 수정된 내부 상태를 가중치와 곱해 우리가 우너하는 출력의 모양으로 만든다. 예를 들어 매 시각마다 단일한 연속값으로 된 예측값을 원한다면(hidden_size, 1) 모양의 가중치 행렬을 곱하면 된다.\n","\n","그 결과 내부 상태는 입력과 이전 시각의 내부 상태로부터 결정되며, 출력은 새로운 내부 상태가 전결합층을 거친 결과가 된다."],"metadata":{"id":"RHcaYPBOIK2r"}},{"cell_type":"markdown","source":["순방향 계산"],"metadata":{"id":"7ZpGmVADJi6q"}},{"cell_type":"code","source":["def forward(self,\n","            x_in: ndarray,\n","            H_in: ndarray,\n","            params_dict: Dict[str, Dict[str, ndarray]]) -> Tuple[ndarray]:\n","  \"\"\"\n","  param x: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","  param H_prev: 모양이 (bathc_size, hidden_size)인 넘파이 배열\n","  return self.x_out: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","  return self.H: 모양이 (batch_size, hidden_size)인 넘파이 배열\n","  \"\"\"\n","  self.X_in = x_in\n","  self.H_in = H_in\n","\n","  self.Z = np.column_stack((x_in, H_in))\n","\n","  self.H_int = np.dot(self.Z, params_dict['W_f']['value']) + params_dict['B_f']['value']\n","\n","  self.H_out = tanh(self.H_int)\n","\n","  self.X_out = np.dot(self.H_out, params_dict['W_v']['value']) + params_dict['B_v']['value']\n","\n","  return self.X_out, self.H_out"],"metadata":{"id":"CP3BeGETvhmq","executionInfo":{"status":"ok","timestamp":1642825197309,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["역방향 계산\n","\n","RNNNode의 출력에 대한 소신의 기울기가 주어졌을 때 이 기울기에 따라 입력에 대한 손실의 기울기를 계산하는 과정이다."],"metadata":{"id":"f6amy5ziKtKN"}},{"cell_type":"code","source":["def backward(self,\n","             X_out_grad: ndarray,\n","             H_out_grad: ndarray,\n","             params_dict: Dict[str, Dict[str, ndarray]]) -> Tuple[ndarray]:\n","  \"\"\"\n","  param x_out_grad: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","  param h_out_grad: 모양이 (batch_size, hidden_size)인 넘파이 배열\n","  param RNN_Params: RNN_Params 객체\n","  return x_in_grad: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","  return h_in_grad: 모양이 (batch_size, hidden_size)인 넘파이 배열\n","  \"\"\"\n","\n","  assert_same_shape(X_out_grad, self.X_out)\n","  assert_same_shape(H_out_grad, self.H_out)\n","\n","  params_dict['B_v']['deriv'] += X_out_grad.sum(axis = 0)\n","  params_dict['W_v']['deriv'] += np.dot(self.H_out.T, X_out_grad)\n","\n","  dh = np.dot(X_out_grad, params_dict['W_v']['value'].T)\n","  dh += H_out_grad\n","\n","  dH_int = dh * dtanh(self.H_int)\n","\n","  params_dict['B_f']['deriv'] += dH_int.sum(axis = 0)\n","  params_dict['W_f']['deriv'] += np.dot(self.Z.T, dH_int)\n","\n","  dz = np.dot(dH_int, params_dict['W_f']['value'].T)\n","\n","  X_in_grad = dz[:, :self.X_in.shape[1]]\n","  H_in_grad = dz[:, self.X_in.shape[1]:]\n","\n","  assert_same_shape(X_out_grad, self.X_out)\n","  assert_same_shape(H_out_grad, self.H_out)\n","\n","  return X_in_grad, H_in_grad"],"metadata":{"id":"cQdfmvpNKksm","executionInfo":{"status":"ok","timestamp":1642825197309,"user_tz":-540,"elapsed":8,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["RNNNode"],"metadata":{"id":"b_XpOB5tSv_Z"}},{"cell_type":"code","source":["class RNNNode(object):\n","\n","  def __init__(self):\n","    pass\n","\n","  def forward(self,\n","            x_in: ndarray,\n","            H_in: ndarray,\n","            params_dict: Dict[str, Dict[str, ndarray]]) -> Tuple[ndarray]:\n","    \"\"\"\n","    param x: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","    param H_prev: 모양이 (bathc_size, hidden_size)인 넘파이 배열\n","    return self.x_out: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","    return self.H: 모양이 (batch_size, hidden_size)인 넘파이 배열\n","    \"\"\"\n","    self.X_in = x_in\n","    self.H_in = H_in\n","\n","    self.Z = np.column_stack((x_in, H_in))\n","\n","    self.H_int = np.dot(self.Z, params_dict['W_f']['value']) + params_dict['B_f']['value']\n","\n","    self.H_out = tanh(self.H_int)\n","\n","    self.X_out = np.dot(self.H_out, params_dict['W_v']['value']) + params_dict['B_v']['value']\n","\n","    return self.X_out, self.H_out\n","\n","  def backward(self,\n","             X_out_grad: ndarray,\n","             H_out_grad: ndarray,\n","             params_dict: Dict[str, Dict[str, ndarray]]) -> Tuple[ndarray]:\n","    \"\"\"\n","    param x_out_grad: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","    param h_out_grad: 모양이 (batch_size, hidden_size)인 넘파이 배열\n","    param RNN_Params: RNN_Params 객체\n","    return x_in_grad: 모양이 (batch_size, vocab_size)인 넘파이 배열\n","    return h_in_grad: 모양이 (batch_size, hidden_size)인 넘파이 배열\n","    \"\"\"\n","\n","    assert_same_shape(X_out_grad, self.X_out)\n","    assert_same_shape(H_out_grad, self.H_out)\n","\n","    params_dict['B_v']['deriv'] += X_out_grad.sum(axis = 0)\n","    params_dict['W_v']['deriv'] += np.dot(self.H_out.T, X_out_grad)\n","\n","    dh = np.dot(X_out_grad, params_dict['W_v']['value'].T)\n","    dh += H_out_grad\n","\n","    dH_int = dh * dtanh(self.H_int)\n","\n","    params_dict['B_f']['deriv'] += dH_int.sum(axis = 0)\n","    params_dict['W_f']['deriv'] += np.dot(self.Z.T, dH_int)\n","\n","    dz = np.dot(dH_int, params_dict['W_f']['value'].T)\n","\n","    X_in_grad = dz[:, :self.X_in.shape[1]]\n","    H_in_grad = dz[:, self.X_in.shape[1]:]\n","\n","    assert_same_shape(X_out_grad, self.X_out)\n","    assert_same_shape(H_out_grad, self.H_out)\n","\n","    return X_in_grad, H_in_grad"],"metadata":{"id":"B1bHCGNdSx4u","executionInfo":{"status":"ok","timestamp":1642825197566,"user_tz":-540,"elapsed":265,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["RNNLayer"],"metadata":{"id":"KYjtupoZTHtg"}},{"cell_type":"code","source":["class RNNLayer(object):\n","\n","  def __init__(self,\n","               hidden_size: int,\n","               output_size: int,\n","               weight_scale: float = None):\n","    \"\"\"\n","    param sequence_length: int - 연속열의 길이\n","    param vocab_size: int - 사용되는 글자의 가짓수\n","    param hidden_size: int - 본 노드가 속한 LSTM_Layer의 은닉 뉴런 수\n","    param learning_rate: float - 학습률\n","    \"\"\"\n","\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.weight_scale = weight_scale\n","    self.start_H = np.zeros((1, hidden_size))\n","    self.first = True\n","\n","  def _init_params(self, \n","                   input_: ndarray):\n","    \n","    self.vocab_size = input_.shape[2]\n","\n","    if not self.weight_scale:\n","      self.weight_scale = 2 / (self.vocab_size + self.output_size)\n","\n","    self.params = {}\n","    self.params['W_f']  = {}\n","    self.params['B_f']  = {}\n","    self.params['W_v']  = {}\n","    self.params['B_v']  = {}\n","\n","    self.params['W_f']['value'] = np.random.normal(loc = 0.0,\n","                                                   scale = self.weight_scale,\n","                                                   size = (self.hidden_size + self.vocab_size, self.hidden_size))\n","    self.params['B_f']['value'] = np.random.normal(loc = 0.0,\n","                                                   scale = self.weight_scale,\n","                                                   size = (1, self.hidden_size))\n","    self.params['W_v']['value'] = np.random.normal(loc = 0.0,\n","                                                   scale = self.weight_scale,\n","                                                   size = (self.hidden_size, self.output_size))\n","    self.params['B_v']['value'] = np.random.normal(loc = 0.0,\n","                                                   scale = self.weight_scale,\n","                                                   size = (1, self.output_size))\n","    \n","    self.params['W_f']['deriv'] = np.zeros_like(self.params['W_f']['value'])\n","    self.params['B_f']['deriv'] = np.zeros_like(self.params['B_f']['value'])\n","    self.params['W_v']['deriv'] = np.zeros_like(self.params['W_v']['value'])\n","    self.params['B_v']['deriv'] = np.zeros_like(self.params['B_v']['value'])\n","\n","    self.cells = [RNNNode() for x in range(input_.shape[1])]\n","\n","  def _clear_gradients(self):\n","    for key in self.params.keys():\n","      self.params[key]['deriv'] = np.zeros_like(self.params[key]['deriv'])\n","\n","  def forward(self, x_seq_in: ndarray):\n","    \"\"\"\n","    param x_seq_in: 모양이 (batch_size, sequence_length, vocab_size)인 넘파이 배열\n","    return x_seq_out: 모양이 (batch_size, sequence_length, output_size)인 넘파이 배열\n","    \"\"\"\n","    if self.first:\n","      self._init_params(x_seq_in)\n","      self.first = False\n","\n","    batch_size = x_seq_in.shape[0]\n","\n","    H_in = np.copy(self.start_H)\n","\n","    H_in = np.repeat(H_in, batch_size, axis = 0)\n","\n","    sequence_length = x_seq_in.shape[1]\n","\n","    x_seq_out = np.zeros((batch_size, sequence_length, self.output_size))\n","\n","    for t in range(sequence_length):\n","      x_in = x_seq_in[:, t, :]\n","      y_out, H_in = self.cells[t].forward(x_in, H_in, self.params)\n","      x_seq_out[:, t, :] = y_out\n","\n","    self.start_H = H_in.mean(axis = 0, keepdims = True)\n","\n","    return x_seq_out\n","\n","  def backward(self, x_seq_out_grad: ndarray):\n","    \"\"\"\n","    param loss_grad: 모양이 (batch_size, sequence_length, vocab_size)인 넘파이 배열\n","    return loss_grad_out: 모양이 (batch_size, sequence_length, vocab_size)인 넘파이 배열\n","    \"\"\"\n","    batch_size = x_seq_out_grad.shape[0]\n","\n","    h_in_grad = np.zeros((batch_size, self.hidden_size))\n","\n","    sequence_length = x_seq_out_grad.shape[1]\n","\n","    x_seq_in_grad = np.zeros((batch_size, sequence_length, self.vocab_size))\n","\n","    for t in reversed(range(sequence_length)):\n","      x_out_grad = x_seq_out_grad[:, t, :]\n","      grad_out, h_in_grad = self.cells[t].backward(x_out_grad, h_in_grad, self.params)\n","\n","      x_seq_in_grad[:, t, :] = grad_out\n","\n","    return x_seq_in_grad"],"metadata":{"id":"ce6sdAUxTJYM","executionInfo":{"status":"ok","timestamp":1642825197567,"user_tz":-540,"elapsed":5,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["RNNModel"],"metadata":{"id":"e8dJVpH50M7A"}},{"cell_type":"code","source":["class RNNModel(object):\n","  \"\"\"\n","  이 클래스는 입력과 목표값으로 신경망을 실제로 학습하며 손실을 계산한다.\n","  \"\"\"\n","  def __init__(self,\n","               layers: List[RNNLayer],\n","               sequence_length: int,\n","               vocab_size: int,\n","               loss: Loss):\n","    \"\"\"\n","    param num_layers: int - 신경망의 층 수\n","    param sequence_length: int - 입력받을 연속열의 길이\n","    param vocab_size: int - 사용되는 글자의 가짓수\n","    param hidden_size: int - 각 층의 은닉 뉴런 수\n","    \"\"\"\n","    self.layers = layers\n","    self.vocab_size = vocab_size\n","    self.sequence_length = sequence_length\n","    self.loss = loss\n","    for layer in self.layers:\n","      setattr(layer, 'sequence_length', sequence_length)\n","\n","  def forward(self, x_batch: ndarray):\n","    \"\"\"\n","    param inputs: list of integers - 신경망에 입력되는 연속열,\n","    연속열의 각 글자에 해당하는 정수의 리스트 형태다.\n","    returns x_batch_in: 모양이 (batch_size, sequence_length, vocab_size)인 넘파이 배열\n","    \"\"\"\n","    for layer in self.layers:\n","      x_batch = layer.forward(x_batch)\n","\n","    return x_batch\n","\n","  def backward(self, loss_grad: ndarray):\n","    \"\"\"\n","    param loss_grad: 모양이(batch_size, sequence_length, vocab_size)인 넘파이 배열\n","    return loss: float, 평균제곱오차 값\n","    \"\"\"\n","    for layer in reversed(self.layers):\n","      loss_grad = layer.backward(loss_grad)\n","    \n","    return loss_grad\n","\n","  def single_step(self,\n","                  x_batch: ndarray,\n","                  y_batch: ndarray):\n","    \"\"\"\n","    여기서 수행되는 과정\n","    1. 순방향 계산, 소프트맥스 함수 통과\n","    2. 손실 및 손실의 기울기 계산\n","    3. 역방향 계산\n","    4. 파라미터 수정\n","    param inputs: 길이가 sequence_length인 리스트, 입력되는 연속열의 각 글자에 해당하는 정수의 리스트다.\n","    param targets: 길이가 sequence_length인 리스트, 목표값인 글자에 해당하는 정수의 리스트다.\n","    \"\"\"\n","    x_batch_out = self.forward(x_batch)\n","\n","    loss = self.loss.forward(x_batch_out, y_batch)\n","\n","    loss_grad = self.loss.backward()\n","\n","    for layer in self.layers:\n","      layer._clear_gradients()\n","\n","    self.backward(loss_grad)\n","    return loss"],"metadata":{"id":"qn1c5kjK0OWu","executionInfo":{"status":"ok","timestamp":1642825197567,"user_tz":-540,"elapsed":4,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["RNNTrainer"],"metadata":{"id":"wxLvD13R2EGa"}},{"cell_type":"code","source":["class RNNTrainer:\n","  \"\"\"\n","  텍스트 파일과 모델을 전달받아 이어지는 글자를 예측한다.\n","  \"\"\"\n","  def __init__(self,\n","               text_file: str,\n","               model: RNNModel,\n","               optim: RNNOptimizer,\n","               batch_size: int = 32):\n","    self.data = open(text_file, 'r').read()\n","    self.model = model\n","    self.chars = list(set(self.data))\n","    self.vocab_size = len(self.chars)\n","    self.char_to_idx = {ch:i for i, ch in enumerate(self.chars)}\n","    self.idx_to_char = {i:ch for i, ch in enumerate(self.chars)}\n","    self.sequence_length = self.model.sequence_length\n","    self.batch_size = batch_size\n","    self.optim = optim\n","    setattr(self.optim, 'model', self.model)\n","\n","  def _generate_inputs_targets(self,\n","                               start_pos: int):\n","    inputs_indices = np.zeros((self.batch_size, self.sequence_length), dtype = int)\n","    targets_indices = np.zeros((self.batch_size, self.sequence_length), dtype = int)\n","\n","    for i in range(self.batch_size):\n","      inputs_indices[i, :] = np.array([self.char_to_idx[ch] for ch in self.data[start_pos + i: start_pos + self.sequence_length + i]])\n","      targets_indices[i, :] = np.array([self.char_to_idx[ch] for ch in self.data[start_pos + 1 + i: start_pos + self.sequence_length + 1 + i]])\n","\n","    return inputs_indices, targets_indices\n","\n","  def _generate_one_hot_array(self, indices: ndarray):\n","    \"\"\"\n","    param indices: 모양이 (batch_size, sequence_length)인 넘파이 배열\n","    return batch: 모양이 (batch_size, sequence_length, vocab_size)인 넘파이 배열\n","    \"\"\"\n","    batch = []\n","    for seq in indices:\n","      one_hot_sequence = np.zeros((self.sequence_length, self.vocab_size))\n","\n","      for i in range(self.sequence_length):\n","        one_hot_sequence[i, seq[i]] = 1.0\n","\n","      batch.append(one_hot_sequence)\n","\n","    return np.stack(batch)\n","\n","  def sample_output(self,\n","                    input_char: int,\n","                    sample_length: int):\n","    \"\"\"\n","    현재 학습된 모델로 한 글자씩 출력을 생성한다.\n","    param input_char: int - 연속열을 시작하는 글자의 인덱스에 해당하는 정수\n","    param sample_length: int - 생성할 연속열의 길이\n","    return txt: string - 길이가 sample_length이며 모델을 통해 생성한 문자열\n","    \"\"\"\n","    indices = []\n","    \n","    sample_model = deepcopy(self.model)\n","\n","    for i in range(sample_length):\n","      input_char_batch = np.zeros((1, 1, self.vocab_size))\n","      input_char_batch[0, 0, input_char] = 1.0\n","\n","      x_batch_out = sample_model.forward(input_char_batch)\n","      x_softmax = batch_softmax(x_batch_out)\n","      \n","      input_char = np.random.choice(range(self.vocab_size), p = x_softmax.ravel())\n","      indices.append(input_char)\n","\n","    txt = ''.join(self.idx_to_char[idx] for idx in indices)\n","\n","    return txt\n","\n","  def train(self,\n","            num_iterations: int,\n","            sample_every: int = 100):\n","    \"\"\"\n","    '글자 생성기'를 학습\n","    각 반복마다 신경망에 크기가 1인 배치가 입력된다.\n","    num_iterations회 반복한다. 매 반복마다 현재 학습된 모델로 생성한 텍스트가 출력된다.\n","    \"\"\"\n","    plot_iter = np.zeros((0))\n","    plot_loss = np.zeros((0))\n","\n","    num_iter = 0\n","    start_pos = 0\n","\n","    moving_average = deque(maxlen = 100)\n","    while num_iter < num_iterations:\n","\n","      if start_pos + self.sequence_length + self.batch_size + 1 > len(self.data):\n","        start_pos = 0\n","\n","      # 모델 수정\n","      inputs_indices, targets_indices = self._generate_inputs_targets(start_pos)\n","\n","      inputs_batch, targets_batch = self._generate_one_hot_array(inputs_indices), self._generate_one_hot_array(targets_indices)\n","\n","      loss = self.model.single_step(inputs_batch, targets_batch)\n","      self.optim.step()\n","\n","      moving_average.append(loss)\n","      ma_loss = np.mean(moving_average)\n","\n","      start_pos += self.batch_size\n","\n","      plot_iter = np.append(plot_iter, [num_iter])\n","      plot_loss = np.append(plot_loss, [ma_loss])\n","\n","      if num_iter % 100 == 0:\n","        plt.plot(plot_iter, plot_loss)\n","        display.clear_output(wait = True)\n","        plt.show()\n","\n","        sample_text = self.sample_output(self.char_to_idx[self.data[start_pos]], 200)\n","\n","        print(sample_text)\n","\n","      num_iter += 1"],"metadata":{"id":"uSRUR5vj2LBt","executionInfo":{"status":"ok","timestamp":1642825250083,"user_tz":-540,"elapsed":228,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/colab/deep_learning_basic/처음_시작하는_딥러닝"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abONFHAN7XOp","executionInfo":{"status":"ok","timestamp":1642825197807,"user_tz":-540,"elapsed":243,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"outputId":"a7f238ac-e34a-4d23-e067-48cffe5bdec4"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/colab/deep_learning_basic/처음_시작하는_딥러닝\n"]}]},{"cell_type":"code","source":["layers = [RNNLayer(hidden_size = 256, output_size=62)]\n","mod = RNNModel(layers= layers,\n","               vocab_size = 62,\n","               sequence_length = 10,\n","               loss = SoftmaxCrossEntropy())\n","\n","optim = SGD(lr = 0.001, gradient_clipping= True)\n","trainer = RNNTrainer('input.txt', mod, optim)\n","trainer.train(1000, sample_every = 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"rMfkNC766kcp","executionInfo":{"status":"ok","timestamp":1642825290541,"user_tz":-540,"elapsed":38014,"user":{"displayName":"임희진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_oO81oyEPaQrdiS5Ku5ChIDaiAYe3xkkp5CCLOw=s64","userId":"01957954719942143952"}},"outputId":"b50b6e33-d702-4eb5-b4de-366971b77a3c"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["h\n","XAdr theact fere doterr sothd.\n","Th hes eeal: ar mienlacloied doug:\n","Sol hgdV:\n","Aas yuuawveer un: 'epnothy shsorome hee\n","yW nre\n","d;yakeWsryon mad wy yemeyw Ihorhooghe thinr cast lorB your moos yot the Vsy\n"]}]},{"cell_type":"markdown","source":["### 바닐라 RNNNode 클래스의 한계\n","\n","- 보통 RNN으로는 언어 모델링에 필요한 긴 기간에 걸친 의존관계 학습이 어렵다.\n","- RNN의 층이 갖는 내부 상태는 매 시각마다 같은 가중치 행렬이 곱해진다. 어떤 수에 같은 수 x를 계속 반복해서 곱할 때, x < 1이면 그 곱은 0에 가까워지고, x > 1이면 무한히 커진다. 오랜 기간에 걸쳐 내부 상태에 같은 가중치가 계속 곱해지면, 이 가중치에 대한 기울기 역시 매우 작아지거나 커진다.\n","- 그 중 전자를 기울기 소실문제(vanishing gradient)라고 하며, 후자는 기울기 폭발 문제(exploding gradient probelm)이라고 한다."],"metadata":{"id":"NzkVIYG2NLd7"}},{"cell_type":"markdown","source":["### GRUNode\n","\n","- 일반적인 RNN은 내부 상태와 입력을 결합한 다음 예측을 내리기 위해 입력과 내부 상태 중 어떤 정보를 더 중시할 것인가를 가중치를 통해 결정한다. \n","- RNN의 보다 발전된 변종은 좀 더 긴 기간에 걸친 의존관계를 모델링하기 위한 목적으로 고안되었다. 이러한 장기간에 걸친 의존관계의 예로 언어 데이터를 들 수 있는데, 이 의존관계에서 **현재 내부상태를 잊어야 하는 정보**를 얻을 수도 있다.\n","예를 들어 마침효(.)와 쌍점(:)을 언어 모델이 입력받으면 이전에 입력받은 정보는 잊고 이어지는 문자열에 대한 새로운 패턴을 모델링 해야한다는 판단을 내릴 수 있다.\n","\n","- 이런 점이 개선된 RNN으로 **게이트 순환 유닛(GRU)**을 들 수 있다. 게이트 순환 유닛은 이전 시각의 내부 상태가 하나 이상의 '게이트'를 거쳐 전달되기 때문에 붙은 이름이다.\n","\n","  1. 첫 번째 게이트는 평범한 RNN에서 사용하는 연산과 비슷하다. 입력과 내부 상태를 서로 접합한 다음, 가중치 행렬을 곱한다. 그리고 sigmoid 함수에 통과시킨다. 이렇게 출력된 값을 '수정' 게이트라고 한다.\n","  2. 두 번째 게이트는 '리셋'게이트다. 이번에도 입력과 내부 상태를 서로 접합한 다음, 가중치 행렬을 곱하고 sigmoid 함수에 통과시킨다. 여기서 그치지 않고 **이전 시각의 내부 상태를 곱한다.** 신경망은 이전 과정을 통해 입력된 정보를 보고, 내부 상태에서 잊어야 하는 정보를 학습한다.\n","  3. 두 번째 게이트의 출력을 다시 다른 행렬과 곱한 다음 Tanh 함수에 통과시킨다. 이 결과는 새로운 내부 상태의 '후보'로 쓰인다.\n","  4. 마지막으로 새로운 내부 상태의 후보와 수정 게이트 값의 곱을 기존 내부 상태값과 (수정 게이트값 - 1)의 곱에 더해 새로운 내부 상태값으로 삼는다."],"metadata":{"id":"s9T5TPrkNIX-"}}]}